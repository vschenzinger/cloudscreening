{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import scipy.spatial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data; for test purposes, a dataframe with random entries is created here\n",
    "data_all = pd.DataFrame(data=np.random.rand(100,5), columns=['AOD 123', 'AOD_534', 'AOD-501', 'flag', 'UTC'])\n",
    "data_all['flag'] = np.array(data_all['flag'] < 0.5).astype('bool')\n",
    "data_all.sort_values(by='UTC', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining subroutines to cloudscreening\n",
    "\n",
    "# Getting list of columns with AOD\n",
    "def get_AOD_cols(df):\n",
    "    AOD_cols = [col for col in df.columns if col[:3] == 'AOD']\n",
    "    return AOD_cols\n",
    "\n",
    "# Getting array of wavelengths\n",
    "def get_wavelengths(df):\n",
    "    lambdas = [float(col[4:]) for col in df.columns if col[:3] == 'AOD']\n",
    "    return lambdas\n",
    "\n",
    "# Finding column name of reference wavelength\n",
    "def get_ref_column(df, ref_wl):\n",
    "    for col in df.columns:\n",
    "        if col[:3] == 'AOD' and float(col[4:]) == ref_wl: name = col\n",
    "    return name\n",
    "\n",
    "# Calculating Angstrom parameters\n",
    "def calc_angstrom(tau, lambdas):\n",
    "    # tau in shape (n_time, n_wavelengths)\n",
    "    # alpha is the linear coefficient, gamma the quadratic, beta is the constant term\n",
    "    alpha = []\n",
    "    beta = []\n",
    "    gamma = []\n",
    "    x = np.log(lambdas)\n",
    "    y = np.log(tau)\n",
    "    ntime, ntau = np.shape(tau)\n",
    "    for k in range(ntime):\n",
    "        if np.any(np.isnan(y[k,:])):\n",
    "            alpha = np.append(alpha, np.nan)\n",
    "            beta = np.append(beta, np.nan)\n",
    "            gamma = np.append(gamma, np.nan)\n",
    "        else:\n",
    "            # Linear fit for alpha and beta\n",
    "            fit_l = np.polynomial.polynomial.Polynomial.fit(x, y[k,:], 1)\n",
    "            coeffs = fit_l.convert().coef # Convert to array of coefficients, index represents exponent\n",
    "            alpha = np.append(alpha, -coeffs[1])\n",
    "            beta = np.append(beta, np.exp(coeffs[0]))\n",
    "            # Quadratic fit for gamma\n",
    "            fit_q = np.polynomial.polynomial.Polynomial.fit(x, y[k,:], 2)\n",
    "            coeffs = fit_q.convert().coef # Convert to array of coefficients, index represents exponent\n",
    "            gamma = np.append(gamma, coeffs[2])\n",
    "    return alpha, beta, gamma\n",
    "\n",
    "# Calculating distance to nearest neighbours\n",
    "def cluster_k_nearest(X_norm, flag, k):\n",
    "    if np.sum(flag) > 0:\n",
    "        kdt = scipy.spatial.cKDTree(X_norm[~flag, :]) # Establish tree on non-flagged datapoints only\n",
    "    else:\n",
    "        kdt = scipy.spatial.cKDTree(X_norm)\n",
    "    dists, neighs = kdt.query(X_norm, k) # Calculate nearest neighbours - non-flagged points will have themselves as 1st NN\n",
    "    avg_dists = np.nanmean(dists, axis=1)\n",
    "    return avg_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloudscreening routine according to a nearest neighbour algorithm\n",
    "# Input: \n",
    "# Dataframe with time in hours as float labelled 'UTC' and AOD values labelled as 'AOD?wavelength', \n",
    "# where ? is an arbitrary separator, and wavelength is given in units of nm, e.g. 'AOD 501' or 'AOD_1020'\n",
    "# If data is preprocessed and includes low quality, flag refers to the respective quality column (bool)\n",
    "# Optional: \n",
    "# reference_wavelength: Wavelength to be used as dimension in clustering, default 501\n",
    "# scaling: Dictionary of floats by which dtau/dt, alpha, gamma gets divided by\n",
    "#          the higher the number, the less weight the variable has\n",
    "# k: Number of nearest neighbours to be used, default 20\n",
    "# limit: If score exceeds limit, flagged as cloudy, default 0.012\n",
    "# Returns:\n",
    "# Boolean array whether point is cloudy or not\n",
    "# If limit is set to None, the distance to nearest neighbours is returned\n",
    "\n",
    "def cloudscreen(data, reference_lambda = 501, flag_label = None, \n",
    "                scaling = {'dtaudt': 12., 'alpha': 10., 'gamma': 20.}, k = 20, limit = 0.012):\n",
    "    if flag_label:\n",
    "        flag = data[flag_label]\n",
    "    else:\n",
    "        flag = []\n",
    "\n",
    "    # Calculate angstrom parameters\n",
    "    alpha, beta, gamma = calc_angstrom(data[get_AOD_cols(data)].values, get_wavelengths(data))\n",
    "                \n",
    "    if len(data) - np.sum(flag) < 5: # Too few datapoints for analysis\n",
    "        scores = np.full(len(data), np.nan)\n",
    "    else:\n",
    "        # Set up dataframe for clustering algorithm\n",
    "        X = pd.DataFrame(columns = ['AOD', 'dadt', 'alpha', 'gamma'])\n",
    "        X['AOD'] = data[get_ref_column(data, reference_lambda)]\n",
    "        X['dadt'] = data[get_ref_column(data, reference_lambda)].diff() / (scaling['dtaudt']*data['UTC'].diff())\n",
    "        X['dadt'].iloc[0] = X['dadt'].iloc[1]\n",
    "        X['alpha'] = alpha/scaling['alpha']\n",
    "        X['gamma'] = gamma/scaling['gamma']\n",
    "\n",
    "        # Turn into array of numbers\n",
    "        X_norm = X.values\n",
    "\n",
    "        # Mean distance is approximately proportional to k;\n",
    "        # if number of points is less than originally intended (by set limit),\n",
    "        # scale the mean distances accordingly\n",
    "        # Can be removed if limit is adjusted anyway\n",
    "        k_factor = 20./k\n",
    "\n",
    "        # Between 5 and 20 possible neighbour points \n",
    "        # e.g. if screening operationally at the beginning of the day \n",
    "        # adapt k for nearest neighbour search\n",
    "        if X_norm.shape[0] - np.sum(flag) < k: \n",
    "            k_ori = k\n",
    "            k = X_norm.shape[0] - np.sum(flag)\n",
    "            k_factor = k_ori/k\n",
    "\n",
    "        scores = k_factor*cluster_k_nearest(X_norm, flag, k)\n",
    "\n",
    "    if limit: return (scores > limit)\n",
    "    else: return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard use\n",
    "# Even if a flag column is present in the data, it\n",
    "# will get ignore as long as 'flag_label' is not set\n",
    "# Returns boolean array of same length as data_all\n",
    "cloudflag = cloudscreen(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customization of scaling, reference wavelength, nearest neighbours etc.\n",
    "# Returns the mean distance to k nearest neighbours (setting limit = None)\n",
    "distances = cloudscreen(data_all, reference_lambda = 123, flag_label = 'flag', \n",
    "                        scaling = {'dtaudt': 12., 'alpha': 10., 'gamma': 20.}, \n",
    "                        k = 10, limit = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
